{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Sprint Challenge\n",
    "## *Data Science Unit 4 Sprint 1*\n",
    "\n",
    "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset/challenge). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
    "\n",
    "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more managable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
    "\n",
    "## Challenge Objectives\n",
    "*Successfully complete these all these objectives to earn a 2. There are more details on each objective further down in the notebook.*\n",
    "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
    "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
    "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
    "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "yelp = pd.read_json('./data/review_sample.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-03-31 16:50:30</td>\n",
       "      <td>0</td>\n",
       "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
       "      <td>1</td>\n",
       "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
       "      <td>10</td>\n",
       "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-16 05:31:03</td>\n",
       "      <td>0</td>\n",
       "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
       "      <td>4</td>\n",
       "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-20 19:14:48</td>\n",
       "      <td>1</td>\n",
       "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
       "      <td>3</td>\n",
       "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
       "      <td>2</td>\n",
       "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-07-13 00:33:45</td>\n",
       "      <td>4</td>\n",
       "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
       "      <td>1</td>\n",
       "      <td>We went here on a night where they closed off ...</td>\n",
       "      <td>5</td>\n",
       "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-30 02:30:01</td>\n",
       "      <td>0</td>\n",
       "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
       "      <td>5</td>\n",
       "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                date  funny  \\\n",
       "0  nDuEqIyRc8YKS1q1fX0CZg     1 2015-03-31 16:50:30      0   \n",
       "1  eMYeEapscbKNqUDCx705hg     0 2015-12-16 05:31:03      0   \n",
       "2  6Q7-wkCPc1KF75jZLOTcMw     1 2010-06-20 19:14:48      1   \n",
       "3  k3zrItO4l9hwfLRwHBDc9w     3 2010-07-13 00:33:45      4   \n",
       "4  6hpfRwGlOzbNv7k5eP9rsQ     1 2018-06-30 02:30:01      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  eZs2tpEJtXPwawvHnHZIgQ      1   \n",
       "1  DoQDWJsNbU0KL1O29l_Xug      4   \n",
       "2  DDOdGU7zh56yQHmUnL1idQ      3   \n",
       "3  LfTMUWnfGFMOfOIyJcwLVA      1   \n",
       "4  zJSUdI7bJ8PNJAg4lnl_Gg      4   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...      10   \n",
       "1  Came here for lunch Togo. Service was quick. S...       0   \n",
       "2  I've been to Vegas dozens of times and had nev...       2   \n",
       "3  We went here on a night where they closed off ...       5   \n",
       "4  3.5 to 4 stars\\n\\nNot bad for the price, $12.9...       5   \n",
       "\n",
       "                  user_id  \n",
       "0  n1LM36qNg4rqGXIcvVXv8w  \n",
       "1  5CgjjDAic2-FAvCtiHpytA  \n",
       "2  BdV-cf3LScmb8kZ7iiBcMA  \n",
       "3  cZZnBqh4gAEy4CdNvJailQ  \n",
       "4  n9QO4ClYAS7h9fpQwa5bhA  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Tokenize Function\n",
    "<a id=\"#p1\"></a>\n",
    "\n",
    "Complete the function `tokenize`. Your function should\n",
    "- accept one document at a time\n",
    "- return a list of tokens\n",
    "\n",
    "You are free to use any method you have learned this week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    # list comprehension method\n",
    "    tokenized = [token for token in simple_preprocess(doc) if token not in STOPWORDS]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [beware, fake, fake, fake, small, business, lo...\n",
       "1    [came, lunch, togo, service, quick, staff, fri...\n",
       "2    [ve, vegas, dozens, times, stepped, foot, circ...\n",
       "3    [went, night, closed, street, party, best, act...\n",
       "4    [stars, bad, price, lunch, seniors, pay, eatin...\n",
       "Name: tokenized, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp['tokenized'] = yelp['text'].apply(tokenize)\n",
    "yelp['tokenized'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Vector Representation\n",
    "<a id=\"#p2\"></a>\n",
    "1. Create a vector representation of the reviews\n",
    "2. Write a fake review and query for the 10 most similiar reviews, print the text of the reviews. Do you notice any patterns?\n",
    "    - Given the size of the dataset, it will probably be best to use a `NearestNeighbors` model for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>001695</th>\n",
       "      <th>007</th>\n",
       "      <th>00a</th>\n",
       "      <th>00am</th>\n",
       "      <th>00ish</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>011802</th>\n",
       "      <th>...</th>\n",
       "      <th>誰も乗車しなくても</th>\n",
       "      <th>豆腐花</th>\n",
       "      <th>質問にも丁寧に答えてくれましたし</th>\n",
       "      <th>車好きさんには</th>\n",
       "      <th>這是一個不錯的選擇</th>\n",
       "      <th>運転しない</th>\n",
       "      <th>運転中も英語で指導があります</th>\n",
       "      <th>食べ物はうまい</th>\n",
       "      <th>餐後點了甜點</th>\n",
       "      <th>３時間後の便</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  001695  007  00a  00am  00ish  00pm   01  011802   ...    \\\n",
       "0  0.0  0.0     0.0  0.0  0.0   0.0    0.0   0.0  0.0     0.0   ...     \n",
       "1  0.0  0.0     0.0  0.0  0.0   0.0    0.0   0.0  0.0     0.0   ...     \n",
       "2  0.0  0.0     0.0  0.0  0.0   0.0    0.0   0.0  0.0     0.0   ...     \n",
       "3  0.0  0.0     0.0  0.0  0.0   0.0    0.0   0.0  0.0     0.0   ...     \n",
       "4  0.0  0.0     0.0  0.0  0.0   0.0    0.0   0.0  0.0     0.0   ...     \n",
       "\n",
       "   誰も乗車しなくても  豆腐花  質問にも丁寧に答えてくれましたし  車好きさんには  這是一個不錯的選擇  運転しない  \\\n",
       "0        0.0  0.0               0.0      0.0        0.0    0.0   \n",
       "1        0.0  0.0               0.0      0.0        0.0    0.0   \n",
       "2        0.0  0.0               0.0      0.0        0.0    0.0   \n",
       "3        0.0  0.0               0.0      0.0        0.0    0.0   \n",
       "4        0.0  0.0               0.0      0.0        0.0    0.0   \n",
       "\n",
       "   運転中も英語で指導があります  食べ物はうまい  餐後點了甜點  ３時間後の便  \n",
       "0             0.0      0.0     0.0     0.0  \n",
       "1             0.0      0.0     0.0     0.0  \n",
       "2             0.0      0.0     0.0     0.0  \n",
       "3             0.0      0.0     0.0     0.0  \n",
       "4             0.0      0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 27289 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple vectorizer\n",
    "\n",
    "vect = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "dtm = vect.fit_transform(yelp['text'].values)\n",
    "dtm = pd.DataFrame(dtm.todense(),columns=vect.get_feature_names())\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=10, p=2, radius=1.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit with Nearest Neighbors model\n",
    "\n",
    "nn  = NearestNeighbors(n_neighbors=10, algorithm='ball_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 21377)\t0.23253263885812106\n",
      "  (0, 20056)\t0.3399934189801272\n",
      "  (0, 18055)\t0.21936416813185233\n",
      "  (0, 9708)\t0.22008194430799846\n",
      "  (0, 8046)\t0.37629126155234505\n",
      "  (0, 2260)\t0.7695331265934292\n"
     ]
    }
   ],
   "source": [
    "# Create bad fake review\n",
    "bad_review = ['This restaurant is a bad place to eat: the service and food is bad']\n",
    "\n",
    "# Transform text\n",
    "bad_review_transformed = vect.transform(bad_review)\n",
    "\n",
    "# Get 10 most similar to bad review\n",
    "_, bad_indices = nn.kneighbors(bad_review_transformed.todense())\n",
    "\n",
    "print(bad_review_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4599    only 1 word describes this place............. ...\n",
       "2518    Don't waste your money. Bad management!!!  Bad...\n",
       "8614    Worst food in Tempe and Phoenix. Every dish ha...\n",
       "8134    Been eating here since they opened and I give ...\n",
       "2990    1 star is what they deserved. No spinach, no s...\n",
       "7398    The food is sooooo amazing! The prices aren't ...\n",
       "508     The place is gorgeous but service is SLOW... A...\n",
       "3808    Multiple pieces of rotten lettuce in my salmon...\n",
       "1091    Absolutely shocked with how bad the food taste...\n",
       "5391    It's good Chinese food. It's fresh and they ar...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print 10 most simliar reviews to bad_review\n",
    "\n",
    "yelp.iloc[bad_indices[0]]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Classification\n",
    "<a id=\"#p3\"></a>\n",
    "Your goal in this section will be to predict `stars` from the review dataset. \n",
    "\n",
    "1. Create a piepline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier. Use that pipeline to estimate a model to predict `stars`. Use the Pipeline to predict a star rating for your fake review from Part 2. \n",
    "2. Tune the entire pipeline with a GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', min_df = 0.05, max_df= 0.90)\n",
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline.\n",
    "pipe = Pipeline([('vect', vectorizer), \n",
    "                 ('clf', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for gridsearch\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': ( 0.75, 1.0),\n",
    "    'vect__min_df': (.02, .05),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators':(5, 10,),\n",
    "    'clf__max_depth':(15,20)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=0.05,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "     ...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit pipeline with data\n",
    "\n",
    "pipe.fit(yelp['text'], yelp['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted star review from fake review:  [1]\n"
     ]
    }
   ],
   "source": [
    "# Predict number of stars for fake bad review\n",
    "\n",
    "print('Predicted star review from fake review: ', pipe.predict(bad_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=0.05,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "     ...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'vect__max_df': (0.75, 1.0), 'vect__min_df': (0.02, 0.05), 'vect__max_features': (500, 1000), 'clf__n_estimators': (5, 10), 'clf__max_depth': (15, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune pipeline with GridSearch \n",
    "\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(yelp['text'], yelp['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5371"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Topic Modeling\n",
    "\n",
    "Let's find out what those yelp reviews are saying! :D\n",
    "\n",
    "1. Estimate a LDA topic model of the review text\n",
    "2. Create 1-2 visualizations of the results\n",
    "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \n",
    "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
    "\n",
    "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import corpora\n",
    "import os, sys, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review(df, tokens):\n",
    "    \"\"\"\n",
    "    Generator function - takes a dataframe with a tokenized column and \n",
    "    yields a tokenized row for processing\n",
    "    \"\"\"\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        token = row[tokens]\n",
    "        yield token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(review(yelp, 'tokenized'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(rev) for rev in review(yelp, 'tokenized')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   iterations=5,\n",
    "                   workers=4,\n",
    "                   num_topics = 6\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "place good food time service\n",
      "\n",
      "Topic 1: \n",
      "food place great service like\n",
      "\n",
      "Topic 2: \n",
      "good food great place time\n",
      "\n",
      "Topic 3: \n",
      "food good place great service\n",
      "\n",
      "Topic 4: \n",
      "food place great good like\n",
      "\n",
      "Topic 5: \n",
      "place good great time food\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in lda.print_topics()]\n",
    "topics = [' '.join(t[0:5]) for t in words]\n",
    "for id, t in enumerate(topics): \n",
    "    print(f\"Topic {id}: \")\n",
    "    print(t, end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weightings for top ten words in each topic.\n",
    "weights = [[float(f) for f in re.findall(r'([\\d.]{5})', topic[1])] \\\n",
    "           for topic in lda.print_topics()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot top 10 words for topic 0\n",
    "\n",
    "import squarify\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "squarify.plot(sizes=weights[0], label=words[0], alpha=0.8)\n",
    "plt.axis('off')\n",
    "plt.title('Topic 0 - Top 10 Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYSIS OF TOPIC MODEL\n",
    "\n",
    "Many reviews use generic terms like \"food, good, great\" to describe their experiences. The top 10 word lists don't provide much sensitive information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goals\n",
    "\n",
    "Complete one of more of these to push your score towards a three: \n",
    "* Incorporate named entity recognition into your analysis\n",
    "* Compare vectorization methods in the classification section\n",
    "* Analyze more (or all) of the yelp dataset - this one is v. hard. \n",
    "* Use a generator object on the reviews file - this would help you with the analyzing the whole dataset.\n",
    "* Incorporate any of the other yelp dataset entities in your analysis (business, users, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
